{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37791139-97be-4ddb-8cbf-c7216db7ed0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saket\\.conda\\envs\\workSparse\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os, sys\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from scipy.spatial import ConvexHull\n",
    "from matplotlib.patches import Polygon, Ellipse\n",
    "sys.path.append(os.path.realpath('./src/'))\n",
    "from utilFuncs import to_np, to_torch\n",
    "from materialEncoder import MaterialEncoder\n",
    "from smallestEllipse import *\n",
    "matplotlib.rcParams['figure.dpi'] = 150\n",
    "matplotlib.rcParams['figure.figsize'] = (20, 10)\n",
    "\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7891cd4c-dd6a-4906-bd80-f8905a937591",
   "metadata": {},
   "source": [
    "### Solidworks database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32ab3559-d61c-4b0f-ad1b-21b67199d2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessData():\n",
    "  df = pd.read_excel('./data/bearingData.xlsx')# solidworksMaterialDatabaseCost # aluminum\n",
    "  dataIdentifier = {'name': df[df.columns[0]], 'className':df[df.columns[1]], 'classID':df[df.columns[2]]} # name of the material and type\n",
    "  trainInfo = np.log10(df[df.columns[3:]].to_numpy())\n",
    "  dataScaleMax = torch.tensor(np.max(trainInfo, axis = 0))\n",
    "  dataScaleMin = torch.tensor(np.min(trainInfo, axis = 0))\n",
    "  normalizedData = (torch.tensor(trainInfo) - dataScaleMin)/(dataScaleMax - dataScaleMin)\n",
    "  trainingData = normalizedData.clone().float()\n",
    "  dataInfo = {'boreD':{'idx':0,'scaleMin':dataScaleMin[0], 'scaleMax':dataScaleMax[0]},\\\n",
    "              'OD':{'idx':1,'scaleMin':dataScaleMin[1], 'scaleMax':dataScaleMax[1]},\\\n",
    "              'Width':{'idx':2,'scaleMin':dataScaleMin[2], 'scaleMax':dataScaleMax[2]},\\\n",
    "              'LoadRating':{'idx':3,'scaleMin':dataScaleMin[3], 'scaleMax':dataScaleMax[3]},\\\n",
    "              'RPM':{'idx':4,'scaleMin':dataScaleMin[4], 'scaleMax':dataScaleMax[4]},\\\n",
    "              'Weight':{'idx':5,'scaleMin':dataScaleMin[5], 'scaleMax':dataScaleMax[5]}}\n",
    "  return trainingData, dataInfo, dataIdentifier, trainInfo\n",
    "trainingData, dataInfo, dataIdentifier, trainInfo = preprocessData()\n",
    "numMaterialsInTrainingData, numFeatures = trainingData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89ee5a7c-ac8b-4c89-bfdd-d960468f1943",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Iter 0 reconLoss 5.80E+01 klLoss 7.53E-04 loss 5.80E+01\n",
      "Learning Rate: 0.002\n",
      "Iter 500 reconLoss 1.40E-01 klLoss 1.40E-02 loss 1.54E-01\n",
      "Learning Rate: 0.002\n",
      "Iter 1000 reconLoss 8.29E-02 klLoss 1.39E-02 loss 9.68E-02\n",
      "Learning Rate: 0.002\n",
      "Iter 1500 reconLoss 5.90E-02 klLoss 1.37E-02 loss 7.27E-02\n",
      "Learning Rate: 0.002\n",
      "Iter 2000 reconLoss 4.53E-02 klLoss 1.34E-02 loss 5.88E-02\n",
      "Learning Rate: 0.002\n",
      "Iter 2500 reconLoss 4.01E-02 klLoss 1.32E-02 loss 5.33E-02\n",
      "Learning Rate: 0.002\n",
      "Iter 3000 reconLoss 3.81E-02 klLoss 1.31E-02 loss 5.12E-02\n",
      "Learning Rate: 0.002\n",
      "Iter 3500 reconLoss 2.88E-02 klLoss 1.29E-02 loss 4.16E-02\n",
      "Learning Rate: 0.002\n",
      "Iter 4000 reconLoss 2.47E-02 klLoss 1.27E-02 loss 3.74E-02\n",
      "Learning Rate: 0.002\n",
      "Iter 4500 reconLoss 2.84E-02 klLoss 1.26E-02 loss 4.10E-02\n",
      "Learning Rate: 0.002\n",
      "Iter 5000 reconLoss 2.13E-02 klLoss 1.25E-02 loss 3.38E-02\n",
      "Learning Rate: 0.002\n",
      "Iter 5500 reconLoss 1.99E-02 klLoss 1.23E-02 loss 3.23E-02\n",
      "Learning Rate: 0.002\n",
      "Iter 6000 reconLoss 3.50E-02 klLoss 1.23E-02 loss 4.73E-02\n",
      "Learning Rate: 0.002\n",
      "Iter 6500 reconLoss 1.55E-02 klLoss 1.21E-02 loss 2.76E-02\n",
      "Learning Rate: 0.002\n",
      "Iter 7000 reconLoss 1.90E-02 klLoss 1.21E-02 loss 3.11E-02\n",
      "Learning Rate: 0.002\n",
      "Iter 7500 reconLoss 1.22E-02 klLoss 1.21E-02 loss 2.43E-02\n",
      "Learning Rate: 0.002\n",
      "Iter 8000 reconLoss 1.02E-02 klLoss 1.19E-02 loss 2.22E-02\n",
      "Learning Rate: 0.002\n",
      "Iter 8500 reconLoss 9.25E-03 klLoss 1.20E-02 loss 2.12E-02\n",
      "Learning Rate: 0.002\n",
      "Iter 9000 reconLoss 1.04E-02 klLoss 1.18E-02 loss 2.23E-02\n",
      "Learning Rate: 0.002\n",
      "Iter 9500 reconLoss 7.22E-03 klLoss 1.18E-02 loss 1.90E-02\n",
      "Learning Rate: 0.002\n",
      "Iter 10000 reconLoss 9.38E-03 klLoss 1.17E-02 loss 2.11E-02\n",
      "Learning Rate: 0.002\n",
      "Iter 10500 reconLoss 7.69E-03 klLoss 1.16E-02 loss 1.93E-02\n",
      "Learning Rate: 0.002\n",
      "Iter 11000 reconLoss 6.29E-03 klLoss 1.15E-02 loss 1.77E-02\n",
      "Learning Rate: 0.002\n",
      "Iter 11500 reconLoss 1.13E-02 klLoss 1.14E-02 loss 2.27E-02\n",
      "Learning Rate: 0.002\n",
      "Iter 12000 reconLoss 6.73E-03 klLoss 1.15E-02 loss 1.83E-02\n",
      "Learning Rate: 0.002\n",
      "Iter 12500 reconLoss 6.14E-03 klLoss 1.13E-02 loss 1.75E-02\n",
      "Learning Rate: 0.002\n",
      "Iter 13000 reconLoss 5.55E-03 klLoss 1.15E-02 loss 1.70E-02\n",
      "Learning Rate: 0.002\n",
      "Iter 13500 reconLoss 1.06E-02 klLoss 1.13E-02 loss 2.19E-02\n",
      "Learning Rate: 0.002\n",
      "Iter 14000 reconLoss 6.98E-03 klLoss 1.12E-02 loss 1.82E-02\n",
      "Learning Rate: 0.002\n",
      "Iter 14500 reconLoss 5.36E-03 klLoss 1.11E-02 loss 1.65E-02\n",
      "Learning Rate: 0.002\n",
      "Iter 15000 reconLoss 5.13E-03 klLoss 1.13E-02 loss 1.64E-02\n",
      "Learning Rate: 0.002\n",
      "Iter 15500 reconLoss 6.16E-03 klLoss 1.11E-02 loss 1.73E-02\n",
      "Learning Rate: 0.002\n",
      "Iter 16000 reconLoss 4.38E-03 klLoss 1.11E-02 loss 1.55E-02\n",
      "Learning Rate: 0.002\n",
      "Iter 16500 reconLoss 6.01E-03 klLoss 1.10E-02 loss 1.71E-02\n",
      "Learning Rate: 0.002\n",
      "Iter 17000 reconLoss 5.72E-03 klLoss 1.10E-02 loss 1.68E-02\n",
      "Learning Rate: 0.002\n",
      "Iter 17500 reconLoss 5.90E-03 klLoss 1.12E-02 loss 1.71E-02\n",
      "Learning Rate: 0.002\n",
      "Iter 18000 reconLoss 1.27E-02 klLoss 1.11E-02 loss 2.38E-02\n",
      "Learning Rate: 0.002\n",
      "Iter 18500 reconLoss 4.07E-03 klLoss 1.11E-02 loss 1.51E-02\n",
      "Learning Rate: 0.002\n",
      "Iter 19000 reconLoss 4.68E-03 klLoss 1.09E-02 loss 1.56E-02\n",
      "Learning Rate: 0.002\n",
      "Iter 19500 reconLoss 4.66E-03 klLoss 1.11E-02 loss 1.57E-02\n",
      "Learning Rate: 0.002\n",
      "training time : 47.29 \n"
     ]
    }
   ],
   "source": [
    "latentDim = 2 \n",
    "hiddenDim = [500]\n",
    "numEpochs = 20000\n",
    "klFactor = 1e-5\n",
    "learningRate = 2e-3\n",
    "savedNet = './data/vaeNet.nt'\n",
    "vaeSettings = {'encoder':{'inputDim':numFeatures, 'hiddenDim':hiddenDim,\\\n",
    "                                          'latentDim':latentDim},\\\n",
    "               'decoder':{'latentDim':latentDim, 'hiddenDim':hiddenDim,\\\n",
    "                                          'outputDim':numFeatures}}\n",
    "materialEncoder = MaterialEncoder(trainingData, dataInfo, dataIdentifier, vaeSettings)\n",
    "# materialEncoder.loadAutoencoderFromFile(savedNet)\n",
    "start = time.perf_counter()\n",
    "convgHistory = materialEncoder.trainAutoencoder(numEpochs, klFactor, savedNet, learningRate)\n",
    "print('training time : {:.2F} '.format(time.perf_counter() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6d9bbc2-03a1-4184-a872-345bb731d94e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a29e4ec-d2ca-4d99-81b1-7f40f342ec11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilFuncs import plotConvergence\n",
    "plotConvergence(convgHistory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8853be58-ebd2-4fde-9672-8f5357b7989a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101, 6)\n"
     ]
    }
   ],
   "source": [
    "print(trainInfo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12594c0-a2f4-4f8e-a631-fd18c836f862",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotConvergence(convg):\n",
    "  plt.figure();\n",
    "  strokes = ['--', '-.', '-', ':']\n",
    "  for ctr, key in enumerate(convg):\n",
    "    y = torch.as_tensor(convg[key]).detach().numpy()\n",
    "    y_mvavg = np.convolve(y, np.ones(20), 'valid') / 20.\n",
    "    plt.semilogy(y_mvavg, strokes[ctr], label = str(key))\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel(str(key))\n",
    "    plt.grid('True')\n",
    "    plt.legend()\n",
    "    plt.savefig('./figures/convergence.pdf')\n",
    "\n",
    "plotConvergence(convgHistory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7694cd-ccd4-4d91-98a9-202373df3e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " \t \t ------RECON ERROR (%)----------\n",
      "Catalog name\tboreD\tOD\tWidth\tLoadRating\tRPM\tWeight\t\n",
      " 1 \t \t 0.4\t 0.8\t 0.0\t 0.7\t 0.6\t 0.0\n",
      " 44 \t \t 0.6\t 0.4\t 0.2\t 1.8\t 0.5\t 0.2\n",
      " 69 \t \t 0.5\t 0.5\t 0.3\t 0.6\t 0.6\t 0.0\n",
      " 85 \t \t 0.2\t 0.3\t 0.2\t 0.8\t 0.3\t 3.4\n",
      " 2 \t \t 0.2\t 0.6\t 0.3\t 2.6\t 0.6\t 0.6\n",
      " 3 \t \t 1.1\t 0.1\t 0.1\t 1.1\t 0.3\t 0.7\n",
      " 4 \t \t 0.6\t 0.4\t 0.3\t 1.2\t 0.9\t 0.8\n",
      " 5 \t \t 0.8\t 0.1\t 0.1\t 3.1\t 0.0\t 0.3\n",
      " 6 \t \t 1.1\t 0.2\t 0.4\t 0.7\t 0.4\t 1.6\n",
      " 7 \t \t 0.2\t 0.2\t 0.1\t 0.5\t 0.7\t 0.4\n",
      " 8 \t \t 1.4\t 0.0\t 0.5\t 1.5\t 1.7\t 0.2\n",
      " 9 \t \t 0.3\t 0.5\t 0.1\t 2.3\t 2.2\t 0.6\n",
      " 10 \t \t 1.9\t 0.1\t 1.0\t 0.1\t 0.4\t 0.7\n",
      " 11 \t \t 0.6\t 0.2\t 0.1\t 2.6\t 0.0\t 0.0\n",
      " 12 \t \t 0.7\t 0.0\t 0.1\t 3.9\t 0.4\t 1.2\n",
      " 13 \t \t 0.1\t 0.3\t 0.1\t 2.3\t 0.6\t 2.0\n",
      " 14 \t \t 0.4\t 0.1\t 0.0\t 0.7\t 0.3\t 0.0\n",
      " 15 \t \t 1.1\t 0.1\t 0.5\t 2.0\t 2.3\t 2.6\n",
      " 16 \t \t 0.3\t 0.4\t 0.0\t 0.1\t 1.6\t 1.5\n",
      " 17 \t \t 1.9\t 0.6\t 0.3\t 1.6\t 3.3\t 0.8\n",
      " 18 \t \t 0.5\t 1.3\t 0.7\t 1.6\t 1.8\t 1.0\n",
      " 19 \t \t 0.0\t 0.2\t 0.2\t 0.0\t 0.3\t 1.2\n",
      " 20 \t \t 0.6\t 0.1\t 0.3\t 1.1\t 0.7\t 1.2\n",
      " 21 \t \t 1.4\t 0.7\t 0.4\t 1.4\t 0.4\t 0.0\n",
      " 22 \t \t 0.9\t 0.8\t 0.1\t 5.0\t 0.1\t 4.4\n",
      " 23 \t \t 0.1\t 0.2\t 0.0\t 1.8\t 0.5\t 0.4\n",
      " 24 \t \t 0.6\t 0.2\t 0.5\t 1.3\t 0.3\t 1.3\n",
      " 25 \t \t 2.6\t 1.7\t 0.2\t 0.7\t 1.3\t 3.0\n",
      " 26 \t \t 0.6\t 0.5\t 0.5\t 0.5\t 0.8\t 8.0\n",
      " 27 \t \t 0.1\t 1.2\t 1.5\t 0.4\t 1.0\t 4.1\n",
      " 28 \t \t 0.1\t 0.0\t 0.0\t 1.4\t 0.5\t 1.5\n",
      " 29 \t \t 0.1\t 0.8\t 0.4\t 0.7\t 1.2\t 1.5\n",
      " 30 \t \t 0.1\t 0.7\t 0.8\t 2.0\t 0.1\t 3.4\n",
      " 31 \t \t 0.4\t 0.8\t 0.5\t 2.2\t 0.5\t 3.2\n",
      " 32 \t \t 0.1\t 0.3\t 0.4\t 2.5\t 0.5\t 0.1\n",
      " 33 \t \t 0.8\t 0.5\t 0.2\t 0.5\t 0.2\t 0.7\n",
      " 34 \t \t 0.3\t 0.2\t 0.1\t 3.6\t 2.8\t 2.5\n",
      " 35 \t \t 0.0\t 0.6\t 0.4\t 0.4\t 1.8\t 6.3\n",
      " 36 \t \t 1.4\t 1.3\t 1.0\t 0.2\t 1.5\t 4.8\n",
      " 37 \t \t 0.9\t 0.4\t 0.5\t 2.9\t 1.0\t 1.8\n",
      " 38 \t \t 0.5\t 0.0\t 0.1\t 0.7\t 0.3\t 0.7\n",
      " 39 \t \t 2.7\t 1.6\t 0.9\t 1.0\t 4.7\t 1.7\n",
      " 40 \t \t 0.5\t 0.7\t 0.5\t 1.3\t 1.1\t 7.6\n",
      " 41 \t \t 0.3\t 1.0\t 0.5\t 1.0\t 0.2\t 1.8\n",
      " 42 \t \t 0.5\t 0.3\t 0.2\t 0.3\t 0.6\t 0.8\n",
      " 43 \t \t 0.5\t 0.1\t 0.2\t 0.3\t 0.2\t 0.3\n",
      " 45 \t \t 1.0\t 0.3\t 0.6\t 3.6\t 0.3\t 0.1\n",
      " 46 \t \t 1.0\t 0.2\t 0.0\t 0.8\t 0.9\t 0.4\n",
      " 47 \t \t 0.8\t 1.3\t 0.6\t 0.7\t 2.9\t 3.2\n",
      " 48 \t \t 0.2\t 0.4\t 0.2\t 1.5\t 0.3\t 1.7\n",
      " 49 \t \t 0.9\t 0.8\t 0.9\t 2.3\t 0.7\t 1.7\n",
      " 50 \t \t 1.3\t 0.3\t 0.2\t 7.8\t 1.5\t 3.8\n",
      " 51 \t \t 0.1\t 0.0\t 0.1\t 3.7\t 0.5\t 0.3\n",
      " 52 \t \t 0.6\t 0.8\t 0.3\t 0.6\t 0.7\t 3.7\n",
      " 53 \t \t 1.2\t 0.3\t 0.2\t 0.5\t 4.3\t 0.9\n",
      " 54 \t \t 0.8\t 0.6\t 0.3\t 3.4\t 2.2\t 2.8\n",
      " 55 \t \t 0.3\t 0.2\t 0.2\t 1.9\t 0.3\t 1.3\n",
      " 56 \t \t 0.9\t 1.1\t 1.0\t 3.0\t 0.8\t 4.4\n",
      " 57 \t \t 1.5\t 1.5\t 0.4\t 0.5\t 2.0\t 4.1\n",
      " 58 \t \t 1.5\t 2.0\t 0.6\t 1.8\t 0.3\t 4.1\n",
      " 59 \t \t 1.2\t 0.3\t 0.5\t 1.8\t 0.2\t 2.7\n",
      " 60 \t \t 0.2\t 0.1\t 0.0\t 3.4\t 0.6\t 1.0\n",
      " 61 \t \t 2.4\t 1.5\t 1.4\t 0.6\t 3.9\t 4.5\n",
      " 62 \t \t 0.9\t 0.5\t 1.0\t 0.2\t 0.4\t 0.5\n",
      " 63 \t \t 0.9\t 0.8\t 0.3\t 1.5\t 3.1\t 1.3\n",
      " 64 \t \t 1.7\t 1.6\t 1.0\t 2.9\t 0.6\t 3.0\n",
      " 65 \t \t 0.9\t 0.4\t 0.3\t 1.4\t 0.4\t 0.9\n",
      " 66 \t \t 0.7\t 0.5\t 0.6\t 0.5\t 0.6\t 1.1\n",
      " 67 \t \t 0.3\t 0.4\t 0.2\t 0.2\t 0.0\t 0.3\n",
      " 68 \t \t 0.0\t 0.2\t 0.2\t 0.9\t 0.3\t 1.2\n",
      " 70 \t \t 0.8\t 0.9\t 0.2\t 1.6\t 0.8\t 0.1\n",
      " 71 \t \t 0.7\t 0.3\t 0.9\t 0.2\t 0.5\t 0.2\n",
      " 72 \t \t 0.3\t 0.2\t 0.1\t 0.9\t 0.3\t 0.6\n",
      " 73 \t \t 0.6\t 0.0\t 0.2\t 0.2\t 0.2\t 2.5\n",
      " 74 \t \t 1.3\t 0.4\t 0.0\t 0.6\t 0.2\t 0.0\n",
      " 75 \t \t 0.1\t 0.3\t 0.2\t 0.0\t 0.1\t 0.1\n",
      " 76 \t \t 0.5\t 0.2\t 0.1\t 1.5\t 0.2\t 0.6\n",
      " 77 \t \t 0.7\t 0.1\t 0.5\t 0.4\t 0.1\t 2.4\n",
      " 78 \t \t 0.4\t 0.3\t 0.1\t 0.4\t 0.4\t 1.1\n",
      " 79 \t \t 0.5\t 0.4\t 2.0\t 1.7\t 0.3\t 1.7\n",
      " 80 \t \t 0.7\t 0.1\t 0.4\t 1.0\t 0.2\t 1.0\n",
      " 81 \t \t 1.9\t 0.3\t 0.0\t 0.7\t 0.1\t 0.4\n",
      " 82 \t \t 0.1\t 0.2\t 0.0\t 1.0\t 0.3\t 0.2\n",
      " 83 \t \t 0.1\t 0.4\t 0.8\t 0.9\t 0.4\t 0.7\n",
      " 84 \t \t 0.7\t 0.0\t 0.6\t 2.1\t 0.3\t 2.0\n",
      " 86 \t \t 0.4\t 0.2\t 0.0\t 0.6\t 0.6\t 5.1\n",
      " 87 \t \t 1.6\t 0.9\t 0.9\t 3.4\t 0.5\t 2.4\n",
      " 88 \t \t 0.4\t 0.3\t 0.3\t 1.0\t 0.4\t 2.2\n",
      " 89 \t \t 0.8\t 0.4\t 0.6\t 1.2\t 0.3\t 3.5\n",
      " 90 \t \t 0.7\t 0.6\t 0.3\t 0.2\t 0.4\t 0.6\n",
      " 91 \t \t 0.3\t 0.0\t 0.8\t 1.4\t 0.7\t 0.4\n",
      " 92 \t \t 0.1\t 0.1\t 0.2\t 0.3\t 0.3\t 0.7\n",
      " 93 \t \t 0.2\t 0.1\t 0.0\t 0.4\t 0.3\t 0.4\n",
      " 94 \t \t 0.2\t 0.2\t 0.1\t 0.3\t 0.1\t 1.4\n",
      " 95 \t \t 0.1\t 0.8\t 0.9\t 1.1\t 0.0\t 0.8\n",
      " 96 \t \t 0.0\t 0.1\t 0.0\t 0.1\t 0.1\t 5.4\n",
      " 97 \t \t 1.0\t 1.0\t 1.2\t 1.1\t 0.2\t 1.9\n",
      " 98 \t \t 0.0\t 0.3\t 0.2\t 0.2\t 0.1\t 1.2\n",
      " 99 \t \t 0.3\t 0.1\t 0.3\t 0.1\t 0.1\t 0.4\n",
      " 100 \t \t 0.6\t 0.3\t 0.5\t 0.3\t 0.3\t 0.2\n",
      " 101 \t \t 0.3\t 0.0\t 0.5\t 1.7\t 0.8\t 1.0\n",
      " max Error\t 2.7\t 2.0\t 2.0\t 7.8\t 4.7\t 8.0\n",
      " Mean Error:\n",
      "tensor([0.6796, 0.4731, 0.3952, 1.3573, 0.7909, 1.6934],\n",
      "       grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "matidxs = np.arange(trainInfo.shape[0]).astype(int)#0,11,20,46,54,69,91,5,92]\n",
    "# matidxs = [13,14,15,48,18,10,9,8,24,25,20,30,69,27,37,4,5,6,73,77,78,85,91,88]\n",
    "props = ['boreD','OD','Width','LoadRating','RPM','Weight']\n",
    "# print([dataIdentifier['name'][i] for i in matidxs])\n",
    "# print('\\t \\t ------TRUE DATA----------')\n",
    "# print('Catalog Name', end = '\\t')\n",
    "# for p in props:\n",
    "#     print(p, end = '\\t')\n",
    "# for i in matidxs:\n",
    "#   print(f\"\\n {dataIdentifier['name'][i]} \\t \", end = '')\n",
    "#   for p in props:\n",
    "#     idx = materialEncoder.dataInfo[p]['idx']\n",
    "#     print('\\t {:.2E}'.format(10.**trainInfo[i,idx]),end='')\n",
    "\n",
    "def unnormalize(val, minval ,maxval):\n",
    "  return 10.**(minval + (maxval-minval)*val)\n",
    "def decodeAll():\n",
    "  vae = materialEncoder.vaeNet\n",
    "  decoded = vae.decoder(vae.encoder.z)\n",
    "  matProp = {'boreD':None,'OD':None,'Width':None,'LoadRating':None,'RPM':None,'Weight':None}\n",
    "\n",
    "  for k in props:\n",
    "    idx = materialEncoder.dataInfo[k]['idx']\n",
    "    scaleMax = materialEncoder.dataInfo[k]['scaleMax']\n",
    "    scaleMin = materialEncoder.dataInfo[k]['scaleMin']\n",
    "    matProp[k] = unnormalize(decoded[:,idx], scaleMin ,scaleMax)#scaleMin + decoded[:,idx]*(scaleMax - scaleMin)\n",
    "  return matProp\n",
    "\n",
    "matProp = decodeAll()\n",
    "# print('\\n \\n \\t \\t ------RECONSTRUCTED DATA----------') \n",
    "# print('Catalog Name', end = '\\t')\n",
    "# for p in props:\n",
    "#     print(p, end = '\\t')\n",
    "  \n",
    "# for i in matidxs:\n",
    "#   print(f\"\\n {dataIdentifier['name'][i]} \\t \", end = '')\n",
    "#   for p in props:\n",
    "#     print('\\t {:.2E}'.format(matProp[p][i]), end='')\n",
    "\n",
    "merr = -1000000000.\n",
    "\n",
    "maxError = {'boreD':merr,'OD':merr,'Width':merr,'LoadRating':merr,'RPM':merr,'Weight':merr}\n",
    "print('\\n \\n \\t \\t ------RECON ERROR (%)----------') \n",
    "print('Catalog name', end = '\\t')\n",
    "errList = torch.zeros(trainInfo.shape[0],6);\n",
    "for p in props:\n",
    "    print(p, end = '\\t')\n",
    "for i in range(trainInfo.shape[0]):\n",
    "  count = 0;\n",
    "\n",
    "  if(i in matidxs): #\n",
    "    print(f\"\\n {dataIdentifier['name'][i]} \\t \", end = '')\n",
    "\n",
    "  for p in props:\n",
    "    idx = materialEncoder.dataInfo[p]['idx']\n",
    "    trueData = 10**trainInfo[i,idx]\n",
    "    reconData = matProp[p][i]\n",
    "    err = torch.abs(100.*(trueData - reconData)/trueData).to('cpu')\n",
    "    errList[i,count] = err\n",
    "    count = count + 1;\n",
    "    if(err > maxError[p]):\n",
    "      maxError[p] = err\n",
    "    if(i in matidxs):\n",
    "      print('\\t {:.1F}'.format(err), end='')\n",
    "  \n",
    "      \n",
    "print('\\n max Error', end = '')\n",
    "for p in props:\n",
    "  print('\\t {:.1F}'.format(maxError[p]), end='')\n",
    "\n",
    "print(\"\\n Mean Error:\")\n",
    "print(torch.mean(errList,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50e3b236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotLatent(ltnt1, ltnt2, plotHull, plotEllipse, annotateHead, saveFileName):\n",
    "    clrs = ['purple', 'green', 'red', 'blue', 'black', 'violet', 'cyan']\n",
    "    mrkrSet = ['x','D','s','p','*','o','P']\n",
    "    colorcol = dataIdentifier['classID']\n",
    "    ptLabel = dataIdentifier['name']\n",
    "    autoencoder = materialEncoder.vaeNet\n",
    "    z = autoencoder.encoder.z.to('cpu').detach().numpy()\n",
    "    fig, ax = plt.subplots()\n",
    "    # matidxs = np.array([13,14,15,48,18,10,9,8,24,20,30,69,27,37,5,6,73,77,78,85,91,88,75,80,82]).astype(int)-2\n",
    "    # matidxs = np.arange(trainInfo.shape[0]).astype(int)\n",
    "    for i in range(np.max(colorcol)+1): \n",
    "      zMat = np.vstack((z[colorcol == i,ltnt1], z[colorcol == i,ltnt2])).T\n",
    "      ax.scatter(zMat[:, 0], zMat[:, 1], marker=mrkrSet[i], c = clrs[i], s = 12)#clrs[i]\n",
    "\n",
    "      if(plotHull):\n",
    "        hull = ConvexHull(zMat)\n",
    "        cent = np.mean(zMat, 0)\n",
    "        pts = []\n",
    "        for pt in zMat[hull.simplices]:\n",
    "            pts.append(pt[0].tolist())\n",
    "            pts.append(pt[1].tolist())\n",
    "  \n",
    "        pts.sort(key=lambda p: np.arctan2(p[1] - cent[1],\n",
    "                                        p[0] - cent[0]))\n",
    "        pts = pts[0::2]  # Deleting duplicates\n",
    "        pts.insert(len(pts), pts[0])\n",
    "        # print(pts)\n",
    "        poly = Polygon(1.1*(np.array(pts)- cent) + cent,\n",
    "                       facecolor= clrs[i], alpha=0.2, edgecolor = 'black') #'black'\n",
    "        poly.set_capstyle('round')\n",
    "        plt.gca().add_patch(poly)\n",
    "        # ax.annotate(dataIdentifier['className'][i], (cent[0], cent[1]), size = 15, c = 'red')\n",
    "        # print(dataIdentifier['className'][i])\n",
    "\n",
    "      if(plotEllipse):\n",
    "        hull = ConvexHull(zMat)\n",
    "        cent = np.mean(zMat, 0)\n",
    "        pts = []\n",
    "        for pt in zMat[hull.simplices]:\n",
    "            pts.append(pt[0].tolist())\n",
    "            pts.append(pt[1].tolist())\n",
    "  \n",
    "        pts.sort(key=lambda p: np.arctan2(p[1] - cent[1],\n",
    "                                        p[0] - cent[0]))\n",
    "        pts = pts[0::2]  # Deleting duplicates\n",
    "        # pts.insert(len(pts), pts[0])\n",
    "        enclosing_ellipse = welzl(np.array(pts, dtype=float))\n",
    "        # plot resulting ellipse\n",
    "        center,a,b,t = enclosing_ellipse\n",
    "        elli = plot_ellipse(enclosing_ellipse, str='k')\n",
    "        ellipse = Ellipse(xy=center, width=2*a, height=2*b, angle=np.degrees(t), edgecolor='k', fc=clrs[i], alpha=0.3, lw=2)\n",
    "        ax.add_patch(ellipse)\n",
    "\n",
    "        ax.annotate('Deep Groove Ball Bearings', xy=(-1.5, 0.5), xytext=(-3,1), size = 14, c = 'black', xycoords='data',textcoords='data',arrowprops=dict(arrowstyle=\"-\"))\n",
    "        ax.annotate('Angular Contact Ball Bearings', xy=(-0.5, -0.5) ,xytext=(0.5,-1.5), size = 14, c = 'black' ,xycoords='data',textcoords='data',arrowprops=dict(arrowstyle=\"-\"))\n",
    "        ax.annotate('Cylindrical Roller Bearings', xy=(0.2,-0.2), xytext=(0.8,-0.5),size = 14, c = 'black', xycoords='data',textcoords='data',arrowprops=dict(arrowstyle=\"-\"))\n",
    "        ax.annotate('Thrust Bearings',xy=(1,1.5),xytext=(1,2), size = 14, c = 'black', xycoords='data',textcoords='data',arrowprops=dict(arrowstyle=\"-\"))\n",
    "        plt.show()\n",
    "\n",
    "        # poly = Polygon(1.1*(np.array(pts)- cent) + cent,\n",
    "        #                facecolor= clrs[i], alpha=0.2, edgecolor = 'black') #'black'\n",
    "        # poly.set_capstyle('round')\n",
    "\n",
    "        # plt.gca().add_patch(poly)\n",
    "        # ax.annotate(dataIdentifier['className'][i], (cent[0], cent[1]), size = 15, c = 'red')\n",
    "        # print(dataIdentifier['className'][i])\n",
    "        # print(i)\n",
    "\n",
    "    matidxs = [ ] \n",
    "    for i, txt in enumerate(ptLabel):\n",
    "      if(annotateHead == False or ( annotateHead == True and  i in matidxs)):\n",
    "        \n",
    "        ax.annotate(txt, (z[i,ltnt1], z[i,ltnt2]), size = 10)\n",
    "        ax.scatter(z[i,ltnt1], z[i,ltnt2], marker='*', c = 'red', s = 56)\n",
    "\n",
    "  #   plt.axis('off')\n",
    "    ticks = [-3, -2,  -1., 0.,  1., 2, 3]\n",
    "    ticklabels = ['-3','-2', '-1', '0','1', '2','3']\n",
    "    plt.xticks(ticks, ticklabels, fontsize=18)\n",
    "    plt.yticks(ticks, ticklabels, fontsize=18)\n",
    "    plt.xlabel('z{:d}'.format(ltnt1), size = 18)\n",
    "    plt.ylabel('z{:d}'.format(ltnt2), size = 18)\n",
    "    minor_ticks = np.arange(-3, 3, 0.1)\n",
    "    ax.set_xticks(minor_ticks, minor=True)\n",
    "    ax.set_yticks(minor_ticks, minor=True)\n",
    "    # Hide the right and top spines\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.set_aspect('equal', 'box')\n",
    "\n",
    "    # plt.grid(which='minor')\n",
    "    plt.grid(visible=None)\n",
    "    plt.savefig(saveFileName,bbox_inches='tight')\n",
    "    \n",
    "    return fig, ax\n",
    "  \n",
    "# plotLatent(0, 1, plotHull = True, plotEllipse = False, annotateHead = True, saveFileName = './figures/latent.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c14291ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Figure size 1924x1027 with 1 Axes>, <AxesSubplot:xlabel='z0', ylabel='z1'>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "font = {'family' : 'normal',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 18}\n",
    "matplotlib.rc('font', **font)\n",
    "plotLatent(0, 1, plotHull = False, plotEllipse = True, annotateHead = True, saveFileName = './figures/Bearinglatent.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "640caaaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family ['normal'] not found. Falling back to DejaVu Sans.\n"
     ]
    }
   ],
   "source": [
    "def plotLatentWithPropertyNew(ltnt1 = 0, ltnt2 = 1):\n",
    "  n = 80\n",
    "  zmin, zmax = -3,3\n",
    "  X,Y = np.meshgrid(np.linspace(zmin, zmax, n), np.linspace(zmin, zmax, n))\n",
    "  Z = torch.zeros((n**2, vaeSettings['encoder']['latentDim'])).to('cpu')\n",
    "  Z[:,ltnt1], Z[:,ltnt2] = to_torch(X.reshape(-1)), to_torch(Y.reshape(-1))\n",
    "\n",
    "  vae = materialEncoder.vaeNet.to('cpu')\n",
    "  trainData_z_np = to_np(vae.encoder.z)\n",
    "  decoded = vae.decoder(Z)\n",
    "\n",
    "\n",
    "\n",
    "  #-------------------------------------------#\n",
    "  props = ['RPM']\n",
    "  cutOff = [2,5]; \n",
    "\n",
    "  for p in props:\n",
    "    idx = materialEncoder.dataInfo[p]['idx']\n",
    "    scaleMax = materialEncoder.dataInfo[p]['scaleMax']\n",
    "    scaleMin = materialEncoder.dataInfo[p]['scaleMin']\n",
    "\n",
    "    matPropVal = to_np(10.**(scaleMin + decoded[:,idx]*(scaleMax - scaleMin)))\n",
    "    levs = np.logspace(np.log10(min(matPropVal))*0.5, np.log10(max(matPropVal)), 40)\n",
    "    fig, ax = plotLatent(0, 1, plotHull = False, plotEllipse = True, annotateHead = True, saveFileName = './figures/Bearinglatent.pdf')\n",
    "    surf = ax.contour(X, Y, (matPropVal.reshape((n,n))), levels = levs, cmap='viridis_r', alpha = 0.6)\n",
    "\n",
    "    # surf = ax.contour(X, Y, (to_np(matPropVal).reshape((n,n))), levels = cutOff, cmap='coolwarm', alpha = 0.3)\n",
    "\n",
    "    # surf = ax.contourf(X, Y, (to_np(matPropVal).reshape((n,n))), levels = cutOff, alpha = 0.2,\\\n",
    "    # colors=['g', 'g', '#C0C0C0'], extend='both')\n",
    "    # surf.cmap.set_over('white')\n",
    "    # surf.cmap.set_under('white')\n",
    "    # surf.changed()\n",
    "\n",
    "    \n",
    "\n",
    "    plt.clabel(surf, inline=False, fontsize=12, fmt ='%0.2f', colors = 'black')\n",
    "    ax.set_xlabel('$z_0$')\n",
    "    ax.set_ylabel('$z_1$')\n",
    "    ax.set_title(p)\n",
    "    cbar = plt.colorbar(surf)\n",
    "    cbar.set_label('({:s})'.format(str(p)))\n",
    "    plt.show()\n",
    "    plt.savefig('./figures/{:s}_latentFieldContours.pdf'.format(p), dpi=200, bbox_inches='tight')\n",
    "\n",
    "  #-------------------------------------------#\n",
    "  \n",
    "\n",
    "plt.close('all')\n",
    "plotLatentWithPropertyNew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0119b833",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c425e398-37d8-4eaa-9f79-1ae4746fb1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotTrueAndReconstructedDistribution():\n",
    "\n",
    "  vae = materialEncoder.vaeNet\n",
    "  trainData_z_np = to_np(vae.encoder.z)\n",
    "  decodedVals = vae.decoder(vae.encoder.z)\n",
    "  \n",
    "  bw = 0.405\n",
    "  fig, ax = plt.subplots(1,2)\n",
    "  #-------------------------------------------#\n",
    "  props = ['youngsModulus','costPerKg','massDensity','yieldStrength']\n",
    "  props = ['youngsModulus','yieldStrength']\n",
    "  for ctr, p in enumerate(props):\n",
    "    idx = materialEncoder.dataInfo[p]['idx']\n",
    "    scaleMax = materialEncoder.dataInfo[p]['scaleMax']\n",
    "    scaleMin = materialEncoder.dataInfo[p]['scaleMin']\n",
    "\n",
    "    matVal_decoded = 10.**(scaleMin + decodedVals[:,idx]*(scaleMax - scaleMin))\n",
    "    matVal_data = 10.**(scaleMin + trainingData[:,idx]*(scaleMax - scaleMin))\n",
    "\n",
    "    sns.set_style('whitegrid')\n",
    "    plt.subplot(1,2,ctr+1)\n",
    "    f = sns.kdeplot(to_np(matVal_decoded), bw_adjust=bw, fill = True, alpha = 0.1, label='decoded')\n",
    "    f = sns.kdeplot(to_np(matVal_data), bw_adjust=bw,  fill = True, alpha = 0.1, linestyle=\"--\", label='actual')\n",
    "    f.set(xlabel = p, ylabel = 'frequency',yticklabels=[])\n",
    "    plt.legend()\n",
    "    plt.axis('auto')\n",
    "    plt.title(p)\n",
    "  \n",
    "  plt.savefig('./figures/trueAndReconstructedDistribution.pdf'.format(p), dpi=200, bbox_inches='tight')\n",
    "\n",
    "plotTrueAndReconstructedDistribution()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36acaf6-facb-45d7-84f9-4abc01d4b6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotLatentPropertyWithGradients(ltnt1 = 0, ltnt2 = 1):\n",
    "  n = 40\n",
    "  zmin, zmax = -2.5,2.5\n",
    "  X,Y = np.meshgrid(np.linspace(zmin, zmax, n), np.linspace(zmin, zmax, n))\n",
    "  Z = torch.zeros((n**2, vaeSettings['encoder']['latentDim']))\n",
    "  Z[:,ltnt1], Z[:,ltnt2] = to_torch(X.reshape(-1)), to_torch(Y.reshape(-1))\n",
    "  Z = torch.tensor(Z, requires_grad = True)\n",
    "  vae = materialEncoder.vaeNet\n",
    "  decodedVals = vae.decoder(Z)\n",
    "\n",
    "\n",
    "\n",
    "  fig, ax = plt.subplots(1,1)\n",
    "  #-------------------------------------------#\n",
    "  props = ['youngsModulus','costPerKg','massDensity','yieldStrength']\n",
    "  props = ['yieldStrength']\n",
    "  for ctr, p in enumerate(props):\n",
    "    idx = materialEncoder.dataInfo[p]['idx']\n",
    "    scaleMax = materialEncoder.dataInfo[p]['scaleMax']\n",
    "    scaleMin = materialEncoder.dataInfo[p]['scaleMin']\n",
    "\n",
    "    matVal_decoded = 10.**(scaleMin + decodedVals[:,idx]*(scaleMax - scaleMin))\n",
    "\n",
    "    dE_dz = to_np(torch.autograd.grad(matVal_decoded, Z, grad_outputs = torch.ones(Z.shape[0]), create_graph = True)[0])\n",
    "    U = dE_dz[:,0] / (1e-4+np.sqrt(dE_dz[:,0]**2 + dE_dz[:,1]**2))\n",
    "    V = dE_dz[:,1] / (1e-4+np.sqrt(dE_dz[:,0]**2 + dE_dz[:,1]**2))\n",
    "    plt.subplot(1,1,ctr+1)\n",
    "    surf = plt.contourf(X, Y, np.log10(to_np(matVal_decoded).reshape((n,n))), levels = 100, cmap='coolwarm', alpha = 0.7)\n",
    "    plt.quiver(X,Y,U,V, headwidth = 0, headlength = 0,headaxislength = 0, color = 'black')\n",
    "#     plt.clabel(surf, inline=False, fontsize=12, fmt ='%0.2F', colors = 'black')\n",
    "    plt.title(p)\n",
    "    plt.xlabel('$z_0$')\n",
    "    plt.ylabel('$z_1$')\n",
    "    cbar = plt.colorbar(surf)\n",
    "#     cbar.set_label('$log_{10}$({:s})'.format(p))\n",
    "  \n",
    "  plt.savefig('./figures/latentSpaceGradient.pdf'.format(p), dpi=200, bbox_inches='tight')\n",
    "  \n",
    "plotLatentPropertyWithGradients()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754b29a7-623f-4673-86a2-45d5328d8f0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('work')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "c8308db7ed4d8db54ee3ca4b196cea43c1c09ddc643cbb9698672ceb6bde4d7f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
